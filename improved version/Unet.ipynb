{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils import data\n",
    "from torchvision import transforms as T\n",
    "import torchvision.transforms.functional as tf\n",
    "from torch.utils.data import DataLoader\n",
    "from math import sqrt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(SEED=42):\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.benchmark = True # keep True if all the input have same size.\n",
    "SEED=42\n",
    "seed_everything(SEED=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#customize datatset\n",
    "class LipTrainDataset(data.Dataset):\n",
    "    def __init__(self, file_path=None, transform=None,table=None):   \n",
    "        self.file_path = file_path\n",
    "        self.transform = transform\n",
    "        self.table = [1] * 256\n",
    "        self.table[0] = 0\n",
    "        # initialize\n",
    "        self.init_all_data(file_path) \n",
    "        return None\n",
    "    def init_all_data(self, file_path):\n",
    "        \n",
    "        # record the path\n",
    "        self.images = []\n",
    "        self.lables = []\n",
    "        #because the whole set is too big, I only number to do a trial first\n",
    "        number = 1000################len(totallist)\n",
    "  \n",
    "        totallist = [line.rstrip('\\n') for line in\n",
    "                        open(os.path.join(self.file_path, 'TrainVal_pose_annotations', 'lip_train_set.csv'), 'r')]\n",
    "        for idx in range(number):##################################################################################\n",
    "            tokens = totallist[idx].split(',')\n",
    "            i = tokens[0].split('.')[0]+'.png'\n",
    "            image_path = os.path.join(self.file_path, 'TrainVal_images', 'TrainVal_images', 'train_images', tokens[0])\n",
    "            lable_path = os.path.join(self.file_path, 'TrainVal_parsing_annotations', 'TrainVal_parsing_annotations','TrainVal_parsing_annotations','train_segmentations', i)\n",
    "            if self.is_valid_image(image_path) and self.is_valid_image(lable_path):###for image and mask all valid\n",
    "                self.images.append(image_path)\n",
    "                self.lables.append(lable_path)   \n",
    "        self.images.sort()\n",
    "        self.lables.sort()\n",
    "        return None               \n",
    "    def is_valid_image(self, img_path):\n",
    "        try:\n",
    "            # 若读取成功，设valid为True\n",
    "            i = Image.open(img_path)\n",
    "            valid = True\n",
    "        except:\n",
    "            # 若读取失败，设valid为False\n",
    "            valid = False\n",
    "            \n",
    "        return valid        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "       #turn image to rgb\n",
    "        image = Image.open(self.images[idx]).convert('RGB')\n",
    "        lable = Image.open(self.lables[idx])\n",
    "        lable=lable.point(self.table,'1')\n",
    "        if self.transform:\n",
    "            image,lable = self.transform(image,lable)\n",
    "\n",
    "                         \n",
    "        return image, lable   \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    \n",
    "class LipValDataset(data.Dataset):\n",
    "    def __init__(self, file_path=None, transform=None,transform2=None,table=None):   \n",
    "        \n",
    "        self.file_path = file_path\n",
    "        self.transform = transform\n",
    "        self.table = [1] * 256\n",
    "        self.table[0] = 0\n",
    "        self.init_all_data(file_path) \n",
    "        return None\n",
    "    def init_all_data(self, file_path):\n",
    "        self.images = []\n",
    "        self.lables = []\n",
    "        number=3000######################len(totallist)\n",
    "        totallist = [line.rstrip('\\n') for line in\n",
    "                        open(os.path.join(self.file_path, 'TrainVal_pose_annotations', 'lip_val_set.csv'), 'r')]\n",
    "        for idx in range(number):###########################################################################\n",
    "            tokens = totallist[idx].split(',')\n",
    "            i = tokens[0].split('.')[0]+'.png'\n",
    "            image_path = os.path.join(self.file_path, 'TrainVal_images', 'TrainVal_images', 'val_images', tokens[0])\n",
    "            lable_path = os.path.join(self.file_path, 'TrainVal_parsing_annotations', 'TrainVal_parsing_annotations','TrainVal_parsing_annotations','val_segmentations', i)\n",
    "            if self.is_valid_image(image_path) and self.is_valid_image(lable_path):\n",
    "                self.images.append(image_path)\n",
    "                self.lables.append(lable_path) \n",
    "        self.images.sort()\n",
    "        self.lables.sort()\n",
    "        return None               \n",
    "    def is_valid_image(self, img_path):\n",
    "        \n",
    "        try:\n",
    "            i = Image.open(img_path)\n",
    "            valid = True\n",
    "        except:\n",
    "            valid = False\n",
    "            \n",
    "        return valid        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.images[idx]).convert('RGB')\n",
    "        lable = Image.open(self.lables[idx])\n",
    "        lable=lable.point(self.table,'1')\n",
    "        if self.transform:\n",
    "            image,lable = self.transform(image,lable)          \n",
    "        return image, lable   \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.images)\n",
    "    \n",
    "class LipTestDataset(data.Dataset):\n",
    "    def __init__(self, file_path=None, transform=None):   \n",
    "       \n",
    "        self.file_path = file_path\n",
    "        self.transform = transform\n",
    "        self.init_all_data(file_path) \n",
    "        return None\n",
    "\n",
    "    def init_all_data(self, file_path):\n",
    "        self.images = []\n",
    "        totallist = [line.rstrip('\\n') for line in\n",
    "                        open(os.path.join(self.file_path, 'Testing_images', 'test_id.txt'), 'r')]\n",
    "        for idx in range(len(totallist)):\n",
    "            tokens = totallist[idx]\n",
    "            i = tokens+'.jpg'\n",
    "            image_path = os.path.join(self.file_path, 'Testing_images', 'Testing_images','testing_images', i)\n",
    "            if self.is_valid_image(image_path):\n",
    "                self.images.append(image_path)       \n",
    "        return None               \n",
    "    def is_valid_image(self, img_path):\n",
    "        \n",
    "        try:\n",
    "            i = Image.open(img_path)\n",
    "            valid = True\n",
    "        except:\n",
    "            valid = False\n",
    "            \n",
    "        return valid        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        image = Image.open(self.images[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)       \n",
    "        return image \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#customize transformation\n",
    "def mytransform1(image,lable):\n",
    "    image = tf.resize(image, (224,224))\n",
    "    lable = tf.resize(lable, (224,224)) \n",
    "    table = [1] * 256\n",
    "    table[0]=0\n",
    "    lable=lable.point(table,'1')\n",
    "    \n",
    "    if random.random() > 0.5:\n",
    "        image = tf.hflip(image)\n",
    "        lable = tf.hflip(lable)\n",
    "    if random.random() > 0.5:\n",
    "        image = tf.vflip(image)\n",
    "        lable = tf.vflip(lable)\n",
    "    image = tf.adjust_contrast(image,random.uniform(0.6,1.5))\n",
    "    image = tf.adjust_brightness(image,random.uniform(0.6,1.5))\n",
    "    image = tf.to_tensor(image)\n",
    "    lable = tf.to_tensor(lable)\n",
    "    image = tf.normalize(image, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    return image, lable\n",
    "def mytransform2(image,lable):\n",
    "    image = tf.resize(image, (224,224))\n",
    "    lable = tf.resize(lable, (224,224)) \n",
    "    table = [1] * 256\n",
    "    table[0]=0\n",
    "    lable=lable.point(table,'1')\n",
    "    image = tf.adjust_contrast(image,random.uniform(0.6,1.5))\n",
    "    image = tf.adjust_brightness(image,random.uniform(0.6,1.5))\n",
    "    image = tf.to_tensor(image)\n",
    "    lable = tf.to_tensor(lable)\n",
    "    image = tf.normalize(image, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    return image, lable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset = LipTrainDataset('../input/singleperson',transform1=mytransform1)\n",
    "train_loader = DataLoader(traindataset, batch_size=16, shuffle=True, num_workers=2)\n",
    "valdataset = LipValDataset('../input/singleperson',transform1=mytransform2)\n",
    "val_loader = DataLoader(valdataset, batch_size=16, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unet\n",
    "import torch.nn as nn\n",
    "\n",
    "from math import sqrt\n",
    "class Double_Conv_Block(nn.Module):\n",
    "    def __init__(self, input_channel, output_channel):\n",
    "        super(Double_Conv_Block, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_channel, output_channel, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            #if there is padding=1,then no crop\n",
    "            nn.BatchNorm2d(output_channel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(output_channel, output_channel, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(output_channel),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_channel): \n",
    "        return self.conv(input_channel)\n",
    "\n",
    "class Up_Conv_Block(nn.Module): #Up sampling\n",
    "    def __init__(self, input_channel, output_channel):\n",
    "        super(Up_Conv_Block, self).__init__()\n",
    "        self.up = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(input_channel, output_channel, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(output_channel),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_channel):\n",
    "        \n",
    "        return self.up(input_channel)\n",
    "\n",
    "\n",
    "class U_Net(nn.Module):\n",
    "    def __init__(self, img_ch=3, output_ch=1):\n",
    "        #img_ch=3 when RGB\n",
    "        #output_ch=1 for our project\n",
    "        super(U_Net, self).__init__()\n",
    "\n",
    "        self.Maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.Conv1 = Double_Conv_Block(input_channel=img_ch, output_channel=64)\n",
    "        self.Conv2 = Double_Conv_Block(input_channel=64, output_channel=128)\n",
    "        self.Conv3 = Double_Conv_Block(input_channel=128, output_channel=256)\n",
    "        self.Conv4 = Double_Conv_Block(input_channel=256, output_channel=512)\n",
    "        self.Conv5 = Double_Conv_Block(input_channel=512, output_channel=1024)\n",
    "\n",
    "        self.Up5 = Up_Conv_Block(input_channel=1024, output_channel=512)\n",
    "        self.Up_Conv_Block5 = Double_Conv_Block(input_channel=1024, output_channel=512)\n",
    "\n",
    "        self.Up4 = Up_Conv_Block(input_channel=512, output_channel=256)\n",
    "        self.Up_Conv_Block4 = Double_Conv_Block(input_channel=512, output_channel=256)\n",
    "\n",
    "        self.Up3 = Up_Conv_Block(input_channel=256, output_channel=128)\n",
    "        self.Up_Conv_Block3 = Double_Conv_Block(input_channel=256, output_channel=128)\n",
    "\n",
    "        self.Up2 = Up_Conv_Block(input_channel=128, output_channel=64)\n",
    "        self.Up_Conv_Block2 = Double_Conv_Block(input_channel=128, output_channel=64)\n",
    "\n",
    "        self.Conv_1x1 = nn.Conv2d(64, output_ch, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        #initialize weight\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # downsample \n",
    "        x1 = self.Conv1(x)\n",
    "\n",
    "        x2 = self.Maxpool(x1)\n",
    "        x2 = self.Conv2(x2)\n",
    "\n",
    "        x3 = self.Maxpool(x2)\n",
    "        x3 = self.Conv3(x3)\n",
    "\n",
    "        x4 = self.Maxpool(x3)\n",
    "        x4 = self.Conv4(x4)\n",
    "\n",
    "        x5 = self.Maxpool(x4)\n",
    "        x5 = self.Conv5(x5)\n",
    "\n",
    "        # up sample + concat \n",
    "        d5 = self.Up5(x5)\n",
    "        d5 = torch.cat((x4, d5), dim=1)\n",
    "\n",
    "        d5 = self.Up_Conv_Block5(d5)\n",
    "\n",
    "        d4 = self.Up4(d5)\n",
    "        d4 = torch.cat((x3, d4), dim=1)\n",
    "        d4 = self.Up_Conv_Block4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        d3 = torch.cat((x2, d3), dim=1)\n",
    "        d3 = self.Up_Conv_Block3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        d2 = torch.cat((x1, d2), dim=1)\n",
    "        d2 = self.Up_Conv_Block2(d2)\n",
    "\n",
    "        d1 = self.Conv_1x1(d2)\n",
    "\n",
    "        return torch.sigmoid(d1)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = U_Net().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)      \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "        return 1 - dice\n",
    "\n",
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):       \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)  \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
    "        Dice_BCE = BCE + dice_loss\n",
    "        \n",
    "        return Dice_BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#criterion = nn.MSELoss()\n",
    "#criterion = DiceLoss(model)\n",
    "criterion = DiceBCELoss(model)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(pred,target):\n",
    "    batch_accs = 0.0\n",
    "    for img in range(pred.size(0)):\n",
    "        pred_inds = pred[img,0,:,:] == 1\n",
    "        target_inds = target[img,0,:,:] == 1\n",
    "        intersection = (pred_inds[target_inds]).sum()\n",
    "        union = pred_inds.sum() + target_inds.sum() - intersection\n",
    "        batch_accs+=(float(intersection)/float(max(union,1)))\n",
    "    return batch_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH=40\n",
    "train_num = len(traindataset)\n",
    "val_num = len(valdataset)\n",
    "losses=[]\n",
    "val_accs=[]\n",
    "train_accs=[]\n",
    "for epoch in range(EPOCH):\n",
    "    # train\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_acc=[]\n",
    "    running_acc = 0.0\n",
    "    for step, data in enumerate(train_loader, start=0):\n",
    "        images, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images.cuda())\n",
    "        o = logits.cuda().data.cpu().numpy()\n",
    "        preds = torch.tensor((o>0.5).astype(np.float32)).to(device)\n",
    "        loss = criterion(logits, labels.cuda())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        running_acc += iou(preds,labels)\n",
    "        train_accurate = running_acc / train_num\n",
    "        train_acc.append(train_accurate)\n",
    "        # print train process\n",
    "        rate = (step+1)/len(train_loader)\n",
    "        a = \"*\" * int(rate * 50)\n",
    "        b = \".\" * int((1 - rate) * 50)\n",
    "        print(\"\\rtrain loss: {:^3.0f}%[{}->{}]{:.4f}\".format(int(rate*100), a, b, loss), end=\"\")\n",
    "    print()\n",
    "    train_accs.append(train_acc[-1])\n",
    "\n",
    "\n",
    "    # validate\n",
    "    torch.cuda.empty_cache()\n",
    "    model.eval()\n",
    "    acc = 0.0  # accumulate accurate number / epoch\n",
    "    with torch.no_grad():\n",
    "        for val_data in val_loader:\n",
    "            val_images, val_labels = val_data\n",
    "            outputs = model(val_images.cuda())  # eval model only have last output layer\n",
    "            # loss = criterion(outputs, test_labels)\n",
    "            o = outputs.cuda().data.cpu().numpy()\n",
    "            preds = torch.tensor((o>0.5).astype(np.float32)).to(device)\n",
    "            \n",
    "\n",
    "            last_eval = {'image': val_images, 'lable': val_labels, 'output': outputs, 'pred': preds}\n",
    "            acc += iou(preds,val_labels)\n",
    "        val_accurate = acc / val_num\n",
    "        val_accs.append(val_accurate)\n",
    "   \n",
    "        print('[epoch %d] train_loss: %.3f  test_accuracy: %.3f train_accuracy: %.3f   ' %\n",
    "              (epoch + 1, running_loss / step, val_accurate,train_accs[-1]))\n",
    "        losses.append(running_loss / step)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(dic):\n",
    "    for k,v in dic.items():\n",
    "        im = torchvision.utils.make_grid(v[:8,:,:,:], nrow=4)\n",
    "        im = im.cuda().data.cpu().numpy().transpose((1, 2, 0))\n",
    "        if k == 'image':\n",
    "            mean = np.array([0.485, 0.456, 0.406])\n",
    "            std = np.array([0.229, 0.224, 0.225])\n",
    "            im = std * im + mean\n",
    "        im = np.clip(im, 0, 1)\n",
    "        plt.imshow(im);       \n",
    "        plt.title(k)\n",
    "        plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(last_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.arange(len(losses))\n",
    "plt.plot(x,losses)\n",
    "plt.title('DiceBCE Loss ')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.arange(len(train_accs))\n",
    "plt.plot(x,train_accs,label='train')\n",
    "plt.plot(x,val_accs,label='validate')\n",
    "plt.title('DiceBCE Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
