{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils import data\n",
    "from torchvision import transforms as T\n",
    "import torchvision.transforms.functional as tf\n",
    "from torch.utils.data import DataLoader\n",
    "from math import sqrt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(SEED=42):\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.benchmark = True # keep True if all the input have same size.\n",
    "SEED=42\n",
    "seed_everything(SEED=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customize dataset\n",
    "class LipTrainDataset(data.Dataset):\n",
    "    def __init__(self, file_path=None, transform1=None,transform2=None,table=None):   \n",
    "        \"\"\"\n",
    "        初始化自定义Dataset类的参数\n",
    "        Attributes\n",
    "            file_path: 字符串，数据集的存储路径，例如‘./UCF101/train’ 或 './UCF101/eval'等\n",
    "            classes  : 列表，每个元素为一个字符串，代表一个子类别，例如['dog', 'airplane', ...]等\n",
    "            transform: 传入一个从torchvision.transforms定义的数据预处理\n",
    "        \"\"\"\n",
    "        self.file_path = file_path\n",
    "        self.transform1 = transform1\n",
    "        self.transform2 = transform2\n",
    "        self.table = [1] * 256\n",
    "        self.table[0] = 0\n",
    "        # 初始化给定文件夹下的所有数据\n",
    "        self.init_all_data(file_path) \n",
    "        return None\n",
    "    def init_all_data(self, file_path):\n",
    "        \"\"\"\n",
    "        初始化该数据集内所有的图像及其对应的标签的位置，保存在self.images和self.labels两个列表内\n",
    "        Attributes\n",
    "            file_path: 字符串，数据集文件夹的存储路径\n",
    "        \"\"\"\n",
    "        # 初始化两个列表，记录该数据集内每一张图片的完整路径及其对应的标签\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        #because the whole set is too big, I only 300 to do a trial first\n",
    "        number = 300################len(totallist)\n",
    "       \n",
    "    # 遍历所有的子类别，并得到每个子类别对应的文件夹路径\n",
    "        \n",
    "        totallist = [line.rstrip('\\n') for line in\n",
    "                        open(os.path.join(self.file_path, 'TrainVal_pose_annotations', 'lip_train_set.csv'), 'r')]\n",
    "        for idx in range(number):##################################################################################\n",
    "            tokens = totallist[idx].split(',')\n",
    "            i = tokens[0].split('.')[0]+'.png'\n",
    "            image_path = os.path.join(self.file_path, 'TrainVal_images', 'TrainVal_images', 'train_images', tokens[0])\n",
    "            label_path = os.path.join(self.file_path, 'TrainVal_parsing_annotations', 'TrainVal_parsing_annotations','TrainVal_parsing_annotations','train_segmentations', i)\n",
    "            if self.is_valid_image(image_path):\n",
    "                self.images.append(image_path)\n",
    "                self.labels.append(label_path)   \n",
    "        self.images.sort()\n",
    "        self.labels.sort()\n",
    "        return None               \n",
    "    def is_valid_image(self, img_path):\n",
    "        \"\"\"\n",
    "        判断图片是否为可以打开的有效文件\n",
    "        Attributes\n",
    "            img_path: 字符串，待检测图片的存储路径\n",
    "        Returns\n",
    "            valid: 布尔变量，True/False分别表示该图片是否可以正常打开\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # 若读取成功，设valid为True\n",
    "            i = Image.open(img_path)\n",
    "            valid = True\n",
    "        except:\n",
    "            # 若读取失败，设valid为False\n",
    "            valid = False\n",
    "            \n",
    "        return valid        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        按给定索引，获取对应的图片及其标签\n",
    "        Attributes\n",
    "            idx: int类型数字，表示目标图像的索引\n",
    "        Returns\n",
    "            image: 一个打开的PIL.Image对象，是PIL库存储图像的一种数据格式（类似于OpenCV利用numpy张量存储图像）\n",
    "            label: \n",
    "        \"\"\"\n",
    "        # 利用PIL.Image.open打开图片，并将其强制转化为RGB格式（防止数据集中混杂灰度图，导致读取出单通道图片，送入网络因矩阵维度不一致而报错）\n",
    "        image = Image.open(self.images[idx]).convert('RGB')\n",
    "        # 获取对应的标签\n",
    "        label = Image.open(self.labels[idx])\n",
    "        label=label.point(self.table,'1')\n",
    "        # 进行预处理的变换\n",
    "        if self.transform1:\n",
    "            image = self.transform1(image)\n",
    "        if self.transform2:\n",
    "            label = self.transform2(label) \n",
    "                         \n",
    "        return image, label   \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        获取数据集中图像的总数，该方法的作用是用于DataLoader去调用，从而获取在给定Batch Size的情况下，一个Epoch的总长，\n",
    "        从而可以在一个Epoch结束时实现shuffle数据集的功能\n",
    "        \"\"\"\n",
    "        return len(self.images)\n",
    "    \n",
    "    \n",
    "class LipValDataset(data.Dataset):\n",
    "    def __init__(self, file_path=None, transform1=None,transform2=None,table=None):   \n",
    "        \n",
    "        self.file_path = file_path\n",
    "        self.transform1 = transform1\n",
    "        self.transform2 = transform2\n",
    "        self.table = [1] * 256\n",
    "        self.table[0] = 0\n",
    "        # 初始化给定文件夹下的所有数据\n",
    "        self.init_all_data(file_path) \n",
    "        return None\n",
    "    def init_all_data(self, file_path):\n",
    "       \n",
    "        # 初始化两个列表，记录该数据集内每一张图片的完整路径及其对应的标签\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        # 遍历所有的子类别，并得到每个子类别对应的文件夹路径\n",
    "        number=300######################len(totallist)\n",
    "        totallist = [line.rstrip('\\n') for line in\n",
    "                        open(os.path.join(self.file_path, 'TrainVal_pose_annotations', 'lip_val_set.csv'), 'r')]\n",
    "        for idx in range(number):###########################################################################\n",
    "            tokens = totallist[idx].split(',')\n",
    "            i = tokens[0].split('.')[0]+'.png'\n",
    "            image_path = os.path.join(self.file_path, 'TrainVal_images', 'TrainVal_images', 'val_images', tokens[0])\n",
    "            label_path = os.path.join(self.file_path, 'TrainVal_parsing_annotations', 'TrainVal_parsing_annotations','TrainVal_parsing_annotations','val_segmentations', i)\n",
    "            if self.is_valid_image(image_path):\n",
    "                self.images.append(image_path)\n",
    "                self.labels.append(label_path) \n",
    "        self.images.sort()\n",
    "        self.labels.sort()\n",
    "        return None               \n",
    "    def is_valid_image(self, img_path):\n",
    "        \n",
    "        try:\n",
    "            # 若读取成功，设valid为True\n",
    "            i = Image.open(img_path)\n",
    "            valid = True\n",
    "        except:\n",
    "            # 若读取失败，设valid为False\n",
    "            valid = False\n",
    "            \n",
    "        return valid        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "       \n",
    "        # 利用PIL.Image.open打开图片，并将其强制转化为RGB格式（防止数据集中混杂灰度图，导致读取出单通道图片，送入网络因矩阵维度不一致而报错）\n",
    "        image = Image.open(self.images[idx]).convert('RGB')\n",
    "        # 获取对应的标签\n",
    "        label = Image.open(self.labels[idx])\n",
    "        label=label.point(self.table,'1')\n",
    "        \n",
    "        # 进行预处理的变换\n",
    "        if self.transform1:\n",
    "            image = self.transform1(image)\n",
    "        if self.transform2:\n",
    "            label = self.transform2(label)              \n",
    "        return image, label   \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.images)\n",
    "    \n",
    "class LipTestDataset(data.Dataset):\n",
    "    def __init__(self, file_path=None, transform=None):   \n",
    "       \n",
    "        self.file_path = file_path\n",
    "        self.transform = transform\n",
    "        # 初始化给定文件夹下的所有数据\n",
    "        self.init_all_data(file_path) \n",
    "        return None\n",
    "\n",
    "    def init_all_data(self, file_path):\n",
    "       \n",
    "        # 初始化两个列表，记录该数据集内每一张图片的完整路径及其对应的标签\n",
    "        self.images = []\n",
    "        # 遍历所有的子类别，并得到每个子类别对应的文件夹路径\n",
    "        \n",
    "        totallist = [line.rstrip('\\n') for line in\n",
    "                        open(os.path.join(self.file_path, 'Testing_images', 'test_id.txt'), 'r')]\n",
    "        for idx in range(len(totallist)):\n",
    "            tokens = totallist[idx]\n",
    "            i = tokens+'.jpg'\n",
    "            image_path = os.path.join(self.file_path, 'Testing_images', 'Testing_images','testing_images', i)\n",
    "            if self.is_valid_image(image_path):\n",
    "                self.images.append(image_path)       \n",
    "        return None               \n",
    "    def is_valid_image(self, img_path):\n",
    "        \n",
    "        try:\n",
    "            # 若读取成功，设valid为True\n",
    "            i = Image.open(img_path)\n",
    "            valid = True\n",
    "        except:\n",
    "            # 若读取失败，设valid为False\n",
    "            valid = False\n",
    "            \n",
    "        return valid        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "       \n",
    "        # 利用PIL.Image.open打开图片，并将其强制转化为RGB格式（防止数据集中混杂灰度图，导致读取出单通道图片，送入网络因矩阵维度不一致而报错）\n",
    "        image = Image.open(self.images[idx]).convert('RGB')\n",
    "        \n",
    "        # 进行预处理的变换\n",
    "        if self.transform:\n",
    "            image = self.transform(image)       \n",
    "        return image \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform because the random crop is random, to guarantee the same operation on lable and image, i do not include them here\n",
    "#another version include same operation on images and lable in another file\n",
    "transform_train = T.Compose([   \n",
    "        T.Resize([256, 256]),\n",
    "        T.CenterCrop([224,224]),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean= [0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "transform_label = T.Compose([   \n",
    "        T.Resize([256, 256]),\n",
    "        T.CenterCrop([224,224]),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.5), (0.5))\n",
    "        ])      \n",
    "# transform_test = T.Compose([\n",
    "#         T.Resize([224, 224]),\n",
    "#         T.ToTensor(),\n",
    "#         T.Normalize(mean= [0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "#         ])  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset = LipTrainDataset('../input/singleperson',transform1=transform_train,transform2=transform_label)\n",
    "train_loader = DataLoader(traindataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "valdataset = LipValDataset('../input/singleperson',transform1=transform_train, transform2=transform_label)\n",
    "val_loader = DataLoader(valdataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "# testdataset = LipTestDataset('../input/singleperson',transform=transform_test)\n",
    "# test_loader = DataLoader(testdataset, batch_size=64, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "from math import sqrt\n",
    "class Double_Conv_Block(nn.Module):\n",
    "    def __init__(self, input_channel, output_channel):\n",
    "        super(Double_Conv_Block, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_channel, output_channel, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            #if there is padding=1,then no crop\n",
    "            nn.BatchNorm2d(output_channel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(output_channel, output_channel, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(output_channel),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_channel): \n",
    "        return self.conv(input_channel)\n",
    "\n",
    "class Up_Conv_Block(nn.Module): #Up sampling\n",
    "    def __init__(self, input_channel, output_channel):\n",
    "        super(Up_Conv_Block, self).__init__()\n",
    "        self.up = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(input_channel, output_channel, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(output_channel),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_channel):\n",
    "        \n",
    "        return self.up(input_channel)\n",
    "\n",
    "\n",
    "class U_Net(nn.Module):\n",
    "    def __init__(self, img_ch=3, output_ch=1):\n",
    "        #img_ch=3 when RGB\n",
    "        #output_ch=1 for our project\n",
    "        super(U_Net, self).__init__()\n",
    "\n",
    "        self.Maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.Conv1 = Double_Conv_Block(input_channel=img_ch, output_channel=64)\n",
    "        self.Conv2 = Double_Conv_Block(input_channel=64, output_channel=128)\n",
    "        self.Conv3 = Double_Conv_Block(input_channel=128, output_channel=256)\n",
    "        self.Conv4 = Double_Conv_Block(input_channel=256, output_channel=512)\n",
    "        self.Conv5 = Double_Conv_Block(input_channel=512, output_channel=1024)\n",
    "\n",
    "        self.Up5 = Up_Conv_Block(input_channel=1024, output_channel=512)\n",
    "        self.Up_Conv_Block5 = Double_Conv_Block(input_channel=1024, output_channel=512)\n",
    "\n",
    "        self.Up4 = Up_Conv_Block(input_channel=512, output_channel=256)\n",
    "        self.Up_Conv_Block4 = Double_Conv_Block(input_channel=512, output_channel=256)\n",
    "\n",
    "        self.Up3 = Up_Conv_Block(input_channel=256, output_channel=128)\n",
    "        self.Up_Conv_Block3 = Double_Conv_Block(input_channel=256, output_channel=128)\n",
    "\n",
    "        self.Up2 = Up_Conv_Block(input_channel=128, output_channel=64)\n",
    "        self.Up_Conv_Block2 = Double_Conv_Block(input_channel=128, output_channel=64)\n",
    "\n",
    "        self.Conv_1x1 = nn.Conv2d(64, output_ch, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        #initialize weight\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # downsample \n",
    "        x1 = self.Conv1(x)\n",
    "\n",
    "        x2 = self.Maxpool(x1)\n",
    "        x2 = self.Conv2(x2)\n",
    "\n",
    "        x3 = self.Maxpool(x2)\n",
    "        x3 = self.Conv3(x3)\n",
    "\n",
    "        x4 = self.Maxpool(x3)\n",
    "        x4 = self.Conv4(x4)\n",
    "\n",
    "        x5 = self.Maxpool(x4)\n",
    "        x5 = self.Conv5(x5)\n",
    "\n",
    "        # up sample + concat \n",
    "        d5 = self.Up5(x5)\n",
    "        d5 = torch.cat((x4, d5), dim=1)\n",
    "\n",
    "        d5 = self.Up_Conv_Block5(d5)\n",
    "\n",
    "        d4 = self.Up4(d5)\n",
    "        d4 = torch.cat((x3, d4), dim=1)\n",
    "        d4 = self.Up_Conv_Block4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        d3 = torch.cat((x2, d3), dim=1)\n",
    "        d3 = self.Up_Conv_Block3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        d2 = torch.cat((x1, d2), dim=1)\n",
    "        d2 = self.Up_Conv_Block2(d2)\n",
    "\n",
    "        d1 = self.Conv_1x1(d2)\n",
    "\n",
    "        return d1\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = U_Net().cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_epochs=70\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "#scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0= 5, T_mult=1, eta_min=0, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloss=[]\n",
    "valloss=[]\n",
    "train_acc=[]\n",
    "val_acc=[]\n",
    "lrs = []\n",
    "iters = len(train_loader)\n",
    "    \n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "                      \n",
    "    for step,(inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(True):\n",
    "            outputs = model(inputs)\n",
    "            o = outputs.cuda().data.cpu().numpy()\n",
    "            preds = torch.tensor((o>0.5).astype(np.float32)).to(device)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "                    \n",
    "            lrs.append((step, optimizer.param_groups[0]['lr']))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #scheduler.step(epoch + step / iters)\n",
    "                        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(traindataset)\n",
    "    epoch_acc = running_corrects.double() / len(traindataset) / outputs.size(-1)**2\n",
    "    trainloss.append(epoch_loss)\n",
    "    train_acc.append(float(epoch_acc))\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "                      \n",
    "    for step,(inputs, labels) in enumerate(val_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            o = outputs.cuda().data.cpu().numpy()\n",
    "            preds = torch.tensor((o>0.5).astype(np.float32)).to(device)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "                    \n",
    "            \n",
    "                        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(valdataset)\n",
    "    epoch_acc = running_corrects.double() / len(valdataset) / outputs.size(-1)**2\n",
    "    valloss.append(epoch_loss)\n",
    "    val_acc.append(float(epoch_acc))\n",
    "\n",
    "    print('Train Loss: {:.4f} Train Acc: {:.4f} Val Loss: {:.4f} Val Acc: {:.4f}'.format(\n",
    "    trainloss[-1], train_acc[-1],valloss[-1], val_acc[-1]))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH=40\n",
    "train_num = len(traindataset)\n",
    "val_num = len(valdataset)\n",
    "losses=[]\n",
    "eval_accs=[]\n",
    "train_accs=[]\n",
    "for epoch in range(EPOCH):\n",
    "    # train\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_acc=[]\n",
    "    acc = 0.0\n",
    "    for step, data in enumerate(train_loader, start=0):\n",
    "        images, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images.cuda())\n",
    "        o = logits.cuda().data.cpu().numpy()\n",
    "        preds = torch.tensor((o>0.5).astype(np.float32)).to(device)\n",
    "        loss = criterion(logits, labels.cuda())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #predict_y = torch.max(logits, dim=1)[1]\n",
    "        acc += (preds == labels.cuda()).sum().item()\n",
    "        train_accurate = acc / train_num /logits.size(-1)**2\n",
    "        train_acc.append(train_accurate)\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        # print train process\n",
    "        rate = (step+1)/len(train_loader)\n",
    "        a = \"*\" * int(rate * 50)\n",
    "        b = \".\" * int((1 - rate) * 50)\n",
    "        print(\"\\rtrain loss: {:^3.0f}%[{}->{}]{:.4f}\".format(int(rate*100), a, b, loss), end=\"\")\n",
    "    print()\n",
    "    train_accs.append(train_acc[-1])\n",
    "\n",
    "    # validate\n",
    "    torch.cuda.empty_cache()\n",
    "    model.eval()\n",
    "    acc = 0.0  # accumulate accurate number / epoch\n",
    "    with torch.no_grad():\n",
    "        for val_data in val_loader:\n",
    "            val_images, val_labels = val_data\n",
    "            outputs = model(val_images.cuda())  # eval model only have last output layer\n",
    "            # loss = criterion(outputs, test_labels)\n",
    "            o = outputs.cuda().data.cpu().numpy()\n",
    "            preds = torch.tensor((o>0.5).astype(np.float32)).to(device)\n",
    "            \n",
    "            acc += (preds == val_labels.cuda()).sum().item()\n",
    "            last_eval = {'image': val_images, 'mask': val_labels, 'output': outputs, 'pred': preds}\n",
    "        val_accurate = acc / val_num / outputs.size(-1)**2\n",
    "        eval_accs.append(val_accurate)\n",
    "        if val_accurate > best_acc:\n",
    "            best_acc = val_accurate\n",
    "            \n",
    "        print('[epoch %d] train_loss: %.3f  test_accuracy: %.3f train_accuracy: %.3f   ' %\n",
    "              (epoch + 1, running_loss / step, val_accurate,train_accs[-1]))\n",
    "        losses.append(running_loss / step)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_performance(dic):##this can visualize the validate part in te last epoch\n",
    "    for k,v in dic.items():\n",
    "        im = torchvision.utils.make_grid(v[:8,:,:,:], nrow=4)\n",
    "        im = im.cuda().data.cpu().numpy().transpose((1, 2, 0))\n",
    "        if k == 'image':\n",
    "            mean = np.array([0.485, 0.456, 0.406])\n",
    "            std = np.array([0.229, 0.224, 0.225])\n",
    "            im = std * im + mean\n",
    "        im = np.clip(im, 0, 1)\n",
    "        plt.imshow(im);\n",
    "        \n",
    "        plt.title(k)\n",
    "        plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_performance(last_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.arange(len(losses))\n",
    "plt.plot(x,losses)\n",
    "#plt.plot(x,eval_losses)\n",
    "plt.title('Loss ')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "#plt.legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.arange(len(train_accs))\n",
    "\n",
    "plt.plot(x,train_accs,label='train')\n",
    "plt.plot(x,eval_accs,label='validate')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.arange(len(train_accs))\n",
    "plt.plot(x,train_accs,label='train')\n",
    "plt.plot(x,eval_accs,label='validate')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
